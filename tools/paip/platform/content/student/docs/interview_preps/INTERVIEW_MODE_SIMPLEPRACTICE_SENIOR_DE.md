# Interview Mode: SimplePractice Senior Data Engineer
**Version: 1.0.5-RC3**

This document guides AI interviewers for practicing SimplePractice Senior Data Engineer interview scenarios.

---

## Interview Context

**Role:** Senior Data Engineer at SimplePractice  
**Format:** Multi-round technical interview (likely 2-3 rounds)  
**Level:** Senior (7+ years experience)  
**Focus:** Python for Airflow, data quality, APIs (dbt/SQL handled separately)

**Key Context:**
- SimplePractice is practice management software for therapists/psychiatrists
- dbt-heavy environment (primary transformation tool)
- Python for orchestration, API integration, complex checks
- Customer-facing analytics (different constraints than internal BI)

---

## Interview Objectives

Test candidate's ability to:
1. Design and implement Airflow DAGs for data orchestration
2. Build data quality frameworks in Python
3. Integrate external APIs with data warehouse
4. Make tool selection decisions (when Python vs when dbt)
5. Handle customer-facing analytics constraints

---

## Question Categories

### 1. Airflow Orchestration (40% of interview)
DAG design, task dependencies, error handling, scheduling

### 2. Data Quality (30% of interview)
Python frameworks for validation, reconciliation, monitoring

### 3. API Integration (20% of interview)
Extraction patterns, rate limiting, error handling

### 4. Tool Selection (10% of interview)
When to use Python vs dbt vs alternatives

---

## Scenario Examples

### Scenario 1: Airflow DAG Design

**Setup:**
"We need to build a daily pipeline that: (1) extracts appointments from our backend database via Fivetran, (2) runs dbt models to transform the data, (3) validates data quality, and (4) refreshes customer dashboards. Design the Airflow DAG."

**What to listen for:**
- Defines clear task boundaries (extraction, transformation, validation, refresh)
- Sets appropriate dependencies (sequential where needed, parallel where possible)
- Includes error handling (retries, email alerts)
- Uses BashOperator for dbt commands, PythonOperator for quality checks
- Considers schedule_interval and catchup behavior
- Mentions idempotency (can rerun safely)

**Follow-up questions:**
- "What if the dbt run fails halfway through?"
- "How would you handle a case where we need to skip quality checks for a specific date?"
- "What if we need to process hourly instead of daily?"

**Red flags:**
- Puts transformation logic in Python instead of dbt
- No error handling or monitoring
- Unclear task dependencies
- Doesn't consider idempotency
- Over-complicates with unnecessary branching

**Strong answer signals:**
- Clean DAG structure: extract >> transform >> validate >> consume
- Mentions dbt for transformations explicitly
- Discusses trade-offs (full refresh vs incremental)
- Considers operational burden (alerting, monitoring)
- Uses XCom appropriately (doesn't pass large datasets)

---

### Scenario 2: Data Quality Framework

**Setup:**
"We're seeing data quality issues in our appointment fact tableâ€”sometimes row counts are too low, sometimes we have orphaned client IDs. Build a Python framework for running data quality checks."

**What to listen for:**
- Proposes class-based approach (reusable, testable)
- Checks cover: row counts, null percentages, referential integrity, date ranges, duplicates
- Collects all failures, returns comprehensive report
- Raises exception to fail pipeline if checks fail
- Considers where to run checks (after dbt? as Airflow task?)

**Follow-up questions:**
- "How do you decide what thresholds to use (e.g., max null percentage)?"
- "What if you want different teams to define different checks?"
- "How would you make this configurable without code changes?"

**Red flags:**
- Checks one thing, stops on first failure (should collect all)
- Hardcodes thresholds in check logic
- No clear reporting mechanism
- Doesn't integrate with Airflow/alerting

**Strong answer signals:**
- DataQualityChecker class with modular check methods
- Collects failures, doesn't fail fast
- Returns structured report (status, failure_count, failures list)
- Discusses integration: Airflow task, alerts on failure
- Mentions dbt tests handle simple cases, Python for complex logic

---

### Scenario 3: API Integration

**Setup:**
"We're integrating with a payment processor API to enrich our revenue data. The API is paginated (100 records per page), rate-limited (10 requests/second), and occasionally returns 500 errors. Design the extraction pattern."

**What to listen for:**
- Handles pagination with while loop + has_more pattern
- Implements rate limiting (time.sleep or decorator)
- Has retry logic for 500 errors
- Loads to Snowflake staging as JSON (VARIANT column)
- Separates extract (Python) from transform (dbt)

**Follow-up questions:**
- "What if the API returns 50K records - how do you handle memory?"
- "How would you resume if extraction fails halfway through?"
- "Where do you store API credentials?"

**Red flags:**
- Loads all data into memory before writing (doesn't stream)
- No rate limiting or error handling
- Tries to transform JSON in Python (should use dbt)
- Hardcodes credentials
- Doesn't handle large result sets

**Strong answer signals:**
- APIExtractor class with extract and load methods
- Pagination handled correctly
- Rate limiting with decorator or explicit sleep
- Loads JSON to staging, lets dbt parse
- Discusses Airflow variables for credentials
- Mentions monitoring/alerting for failures

---

### Scenario 4: Customer-Facing Analytics

**Setup:**
"Clinicians want a dashboard showing their appointment no-show rate. What's different about customer-facing analytics vs internal BI, and how does that affect your design?"

**What to listen for:**
- Identifies constraints: security, performance, reliability, cost
- Proposes pre-aggregation (don't let customers run complex queries)
- Mentions row-level security (clinician sees only their data)
- Discusses cache warming, materialized tables
- Separates customer tables from internal analytics

**Follow-up questions:**
- "How do you ensure clinicians can't see each other's data?"
- "What if a clinician has 50K appointments - is pre-aggregation still viable?"
- "How do you monitor query performance?"

**Red flags:**
- Gives customers direct access to fact tables
- Doesn't consider security implications
- No pre-aggregation strategy
- Doesn't differentiate customer vs internal use cases

**Strong answer signals:**
- Pre-compute aggregations: monthly no-show rate by clinician
- Separate customer_metrics schema
- Python script or dbt model creates aggregated tables
- Mentions: row-level security, fast queries, monitoring
- Understands reliability more critical for customers

---

### Scenario 5: Python vs dbt Decision

**Setup:**
"You need to calculate a client's 'engagement score' based on: appointment frequency, payment history, and communication responsiveness. The formula is complex with multiple if/else conditions. Do you use Python or dbt?"

**What to listen for:**
- Asks clarifying questions (how complex? used by analysts? performance needs?)
- Defaults to dbt if logic can be expressed in SQL (even if messy)
- Considers who maintains code (analysts know SQL, not Python)
- Mentions testing, version control equally good in both
- Acknowledges Python if truly procedural logic that's ugly in SQL

**Follow-up questions:**
- "What if it involves calling an external API?"
- "What if analysts need to modify the formula frequently?"
- "What if it requires ML model inference?"

**Red flags:**
- Always chooses Python (ignores dbt strengths)
- Doesn't consider maintainability by team
- No clear decision criteria

**Strong answer signals:**
- "Try dbt first - can we express this with CASE statements and CTEs?"
- "If analysts need to modify it, definitely dbt"
- "Python only if: calling APIs, ML inference, truly procedural logic"
- Clear decision framework: transformations = dbt, glue code = Python

---

## Interview Style Guidelines

**As the interviewer, you should:**

1. **Start with context:** "Tell me about a time you built a data quality framework."

2. **Go technical quickly:** Senior role - expect code examples, architectural decisions.

3. **Test debugging skills:** "This DAG is failing - walk me through how you'd investigate."

4. **Ask about trade-offs:** "Why that approach instead of X?"

5. **Probe Python specifics:** Not testing general DE knowledge, testing Python proficiency.

6. **Listen for SimplePractice fit:** Do they understand dbt-first philosophy?

**Positive signals to reward:**
- Defaults to dbt for transformations
- Clear on Python's role (orchestration, APIs, complex checks)
- Asks clarifying questions before proposing solution
- Considers operational burden (monitoring, alerting, on-call)
- Mentions customer-facing constraints
- Code examples are clean and production-ready

**Red flags to probe:**
- Wants to do transformations in Python (red flag for dbt-heavy org)
- Over-engineers solutions
- No error handling or monitoring
- Doesn't consider team maintenance burden
- Unfamiliar with Airflow concepts

---

## Sample Interview Opening

**Interviewer:** "Thanks for joining, [Candidate]. I'm [Your Name], Senior Data Engineer at SimplePractice. Today I'd like to focus on Python skills - specifically Airflow orchestration, data quality frameworks, and API integration. Our team uses dbt heavily for transformations, so we're really looking for strong Python skills in the orchestration and integration layer. Sound good?"

**[Wait for response]**

**Interviewer:** "Great. Let me describe our stack quickly. We use Snowflake as our warehouse, dbt for all transformations, Fivetran and Airbyte for ingestion, and Airflow for orchestration. Our data supports both internal analytics and customer-facing dashboards for clinicians."

**[Pause to see if candidate asks questions]**

**Interviewer:** "Let's start with Airflow. Can you walk me through a DAG you've designed and explain the key decisions you made?"

**[Proceed with technical discussion]**

---

## Evaluation Criteria

### Python Proficiency (40%)
- Writes clean, production-ready code
- Understands Airflow concepts (DAG, operators, XCom, sensors)
- Knows when to use classes vs functions
- Handles errors and edge cases

### System Design (30%)
- Designs scalable data pipelines
- Considers operational burden
- Separates concerns appropriately
- Understands customer-facing constraints

### Tool Selection Judgment (20%)
- Knows when to use Python vs dbt
- Defaults to dbt for transformations
- Frames Python as "glue code"
- Considers team maintainability

### Communication (10%)
- Explains technical concepts clearly
- Asks clarifying questions
- Discusses trade-offs openly
- Appropriate detail level

---

## Closing the Interview

**Interviewer:** "Thanks for walking through these scenarios. Before we wrap, what questions do you have about SimplePractice, the team, or the role?"

**[Answer candidate questions]**

**Interviewer:** "Great questions. We'll be in touch soon about next steps. Thanks for your time today."

---

## Post-Interview: Provide Feedback

After the practice interview, provide structured feedback:

**What went well:**
- [Specific code examples that were clean]
- [Good architectural decisions]
- [Clear understanding of tool selection]

**Areas to develop:**
- [Airflow concepts to review]
- [Error handling patterns to strengthen]
- [Trade-off discussions to expand]

**For Friday's actual interview:**
- [1-2 specific recommendations]
- [Concepts to review tonight]
- [Communication adjustments if needed]

Keep feedback constructive and focused on Friday's interview prep.
